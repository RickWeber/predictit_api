---
title: "Predictit API Notebook"
output: html_notebook
---

# Let's use an API

[Predictit](https://www.predictit.org/) is a prediction market that gives pretty good insight into uncertaint events that have yet to happen. They also have an API that gives current data, but I want historical data. So I'll collect it myself.

My basic plan is to build a script that runs every minute (that's how often their API updates), to pull the data from their server, do some processing, and add the new data to an existing dataset. There will be decisions to be made along the way, but let's start by working through the problem.

```{r}
rm(list = ls())
library(tidyverse)
library(jsonlite)

url = 'https://www.predictit.org/api/marketdata/all'

download.file(url,'data.json')

data <- fromJSON("data.json",simplifyDataFrame = TRUE)
head(data)
```

Okay, I've got the data, but I wonder if I can use `readr` to push it directly into a tibble.

```{r}
fromJSON(url)
```

Cool! Although that was all `jsonlite`. The last time I looked at this problem (before getting distracted and wandering off) was about a year ago. And past Rick figured out something that isn't obvious to present Rick: The data is a list of one item and that one item is the dataframe that I actually want. It's named `markets`.

```{r}
pull <- function(){
  fromJSON(url)
}
pull()$markets %>% dim()
data <- pull()$markets
names(data)
```

`contracts` has what I'm really after, I think. Let's look.

```{r}
data$contracts %>% length
```

Just before setting up the git repository for this project there was 184 markets. It looks like 10 markets have been closed in the last 15 minutes. In any case, when I look to closely at data$contracts it bogs everything down. It's too much data at once in 174 individual dataframes. I think I need to unnest this.

```{r}
data_unnest <- data %>%
  unnest()
```
You know what, I'm going to drop some columns I don't care about...

```{r}
data <- data %>%
  select(-image,-url)
data_unnest <- data %>%
  unnest()
head(data_unnest)
```

Alright, we've got a few rows for each market, where each row has a unique value for id1, another image I don't want, and a bunch of prices I do want.

```{r}
names(data_unnest)
data_unnest %>%
  select(id,id1,status:status1,name,name1) %>%
  head()
```

That looks better. I've got id of the market, id of the contract (e.g. "Democrat wins"), status, and some prices. The order doesn't really matter, but it makes it easier for me if I don't have to scroll through the data while I'm figuring things out.

So if I `pull()` the data, `unnest()` it and drop a few columns, I've got pretty much all I want. I might as well convert the timestamp into a proper datetime format to make life easier down the line, but this should be pretty easy.

```{r}
process <- function(){
  # pull the data
  df <- pull()$markets
  # unnest, drop columns
  df <- df %>%
    unnest %>%
    # select(-contains("url" | "image" | "shortName")) # not sure why that isn't working. :(
    select(contains("id"),status:status1,name,name1)
  return(df)
}
process() %>% head()
```

Alright, now I just need to append the data to some existing dataset. The easiest option would be to just save a new csv every minute. But the data would be more useful if it's at least bundled up by day. 

## Old Code
### This is the stuff I found left in this folder from last year.

Okay, I've got the data, but before I worry about gathering a lot of it, let me sort out the process of cleaning it. I'll start with the easiest problem: unnesting the contracts information in the case of binary markets (e.g. "will X happen, yes or no?" as opposed to "which of these several outcomes will happen?").

```{r}
data$markets$contracts
t <- data$markets %>% sample_n(1)
head(t)
```

Ugh. How is my nice looking tibble hiding the fact that it's actually `data$markets` that I'm after?

```{r}
head(data$markets)
```

Let's sort this out from the get go:
```{r}
data <- fromJSON("data.json",simplifyDataFrame = TRUE)
data <- data$markets
# head(data) # That works
t <- data %>% filter(id == 2747)
# head(t) # And more importantly, *that* works
```

Now let's see what's in the contracts folder.

```{r}
t$contracts
```

That's the good stuff. Let me create a simple function to rename things to avoid conflicts when I try to unnest this into the main data frame.

```{r}
# colnames(t$contracts) # NULL
# names(t$contracts) # NULL
# unlist(t$contracts) # nope... that's not gonna do it.
# unnest(t$contracts) # that won't work either...
is(t$contracts)
```

Okay, the data I want is in this list, and I'm not sure how to pull it out. 

```{r}
t2 <- t$contracts[[1]]
t2
```

Oh... that should have been more obvious. Oh well... Now I can tidy up my code:

```{r}
data <- fromJSON("data.json",simplifyDataFrame = TRUE)
data <- data$markets
t <- data %>% filter(id == 2747)
t <- t$contracts[[1]]
```

Technically, all this work I've done has basically boiled down to a lot of code written and deleted. Like good writing, good coding involves a lot of editing. But let me get back to work...

```{r}
colnames(t)[c(1,3)] <- c("contract_id","contract_image")
t
```

I think I can get by only renaming those two columns. Let's try to join it back to the original data.

```{r}
data_cuban <- data %>% filter(id == 2747)
full_join(data_cuban,t)
```

That looks like it'll do what I want. Now let's get ready to wrap it up in a function and apply it to all of the data. I might need to filter the dataset down to binary markets, but maybe it'll just work. So let's try that first.

```{r}
pull_out_contracts <- function(df_row){
  contracts <- df_row$contracts[[1]]
  colnames(contracts)[c(1,3)] <- c("contract_id","contract_image")
  contracts
}
C <- apply(X = data,MARGIN = 1,FUN = function(x) {
  pull_out_contracts(x) %>% full_join(x)
  }
  )
?inner_join
```

Not working, but I'll pick it up later...